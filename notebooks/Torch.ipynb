{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040a6e12-aa98-4698-acd3-bcdf501c780a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentCNN(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SentimentCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentimentCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Linear layers\n",
    "        self.fc1 = nn.Linear(64 * 4, 128)  # assuming the input size to the first linear layer is 64*4\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)  # output layer\n",
    "\n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU activation and max pooling\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten the output for the linear layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Apply linear layers with ReLU activation and dropout\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.dropout(self.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)  # output layer\n",
    "\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = SentimentCNN()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd9ac02-3a3c-4998-b07d-5caebcbd3f19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockPricePredictionModel(\n",
       "  (embedding): Embedding(10000, 300)\n",
       "  (conv1): Conv1d(300, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv3): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (lstm): LSTM(512, 64, batch_first=True)\n",
       "  (fc_news1): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (fc_news2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc_combined1): Linear(in_features=129, out_features=64, bias=True)\n",
       "  (fc_combined2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class StockPricePredictionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_hidden_dim, lstm_num_layers, num_classes):\n",
    "        super(StockPricePredictionModel, self).__init__()\n",
    "\n",
    "        # Embedding layer using GloVe vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight.requires_grad = False  # we do not train the GloVe embeddings\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=512, hidden_size=lstm_hidden_dim, num_layers=lstm_num_layers, batch_first=True)\n",
    "\n",
    "        # Linear layers for news feature extraction\n",
    "        self.fc_news1 = nn.Linear(lstm_hidden_dim, 256)\n",
    "        self.fc_news2 = nn.Linear(256, 128)\n",
    "\n",
    "        # Linear layers for concatenated news and price features\n",
    "        self.fc_combined1 = nn.Linear(128 + 1, 64)  # +1 for the scaled price\n",
    "        self.fc_combined2 = nn.Linear(64, num_classes)  # output layer\n",
    "\n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, news, scaled_price):\n",
    "        # Embedding layer\n",
    "        news = self.embedding(news)\n",
    "\n",
    "        # Convolutional layers with ReLU activation and max pooling\n",
    "        news = news.permute(0, 2, 1)  # batch_size x text_length x embedding_dim -> batch_size x embedding_dim x text_length\n",
    "        news = self.pool(self.relu(self.conv1(news)))\n",
    "        news = self.pool(self.relu(self.conv2(news)))\n",
    "        news = self.pool(self.relu(self.conv3(news)))\n",
    "\n",
    "        # LSTM layer\n",
    "        news = news.permute(0, 2, 1)  # batch_size x embedding_dim x reduced_text_length -> batch_size x reduced_text_length x embedding_dim\n",
    "        news, (hn, cn) = self.lstm(news)\n",
    "        news_features = news[:, -1, :]  # taking the last time step's output\n",
    "\n",
    "        # Pass through linear layers for news\n",
    "        news_features = self.dropout(self.relu(self.fc_news1(news_features)))\n",
    "        news_features = self.dropout(self.relu(self.fc_news2(news_features)))\n",
    "\n",
    "        # Concatenate the scaled price with the news features\n",
    "        combined_features = torch.cat((news_features, scaled_price.unsqueeze(1)), dim=1)\n",
    "\n",
    "        # Pass through linear layers for combined features\n",
    "        combined_features = self.dropout(self.relu(self.fc_combined1(combined_features)))\n",
    "        predictions = self.fc_combined2(combined_features)  # no activation, as this might be a regression problem\n",
    "\n",
    "        return predictions\n",
    "\n",
    "# Parameters for the model (to be adjusted as necessary)\n",
    "vocab_size = 10000  # size of the vocabulary\n",
    "embedding_dim = 300  # dimensionality of GloVe vectors\n",
    "lstm_hidden_dim = 64  # LSTM hidden dimensions\n",
    "lstm_num_layers = 1  # number of layers in LSTM\n",
    "num_classes = 1  # for price prediction, we output a single value\n",
    "\n",
    "# Create the model instance\n",
    "model = StockPricePredictionModel(vocab_size, embedding_dim, lstm_hidden_dim, lstm_num_layers, num_classes)\n",
    "model\n",
    "\n",
    "# Note: The actual GloVe embeddings need to be loaded into the model's embedding layer.\n",
    "# This code assumes that the 'embedding' attribute will be populated with pre-trained GloVe vectors outside of this definition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab1fa95-d98e-4482-ab29-aec704b25c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DJIAPricePredictionModel(\n",
       "  (gru): GRU(2, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DJIAPricePredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(DJIAPricePredictionModel, self).__init__()\n",
    "        \n",
    "        # GRU layer\n",
    "        self.gru = nn.GRU(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Linear layer that maps from hidden state space to price prediction space\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, historical_prices, news_sentiments):\n",
    "        # Concatenate historical prices and news sentiments along feature dimension\n",
    "        combined_input = torch.cat((historical_prices.unsqueeze(-1), news_sentiments.unsqueeze(-1)), dim=2)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        gru_out, _ = self.gru(combined_input)\n",
    "        \n",
    "        # Taking the last time step's output for the final price prediction\n",
    "        last_step_output = gru_out[:, -1, :]\n",
    "        \n",
    "        # Passing the last time step's output to the linear layer\n",
    "        price_prediction = self.fc(last_step_output)\n",
    "        return price_prediction\n",
    "\n",
    "# Parameters for the model\n",
    "input_dim = 2  # historical price and sentiment score\n",
    "hidden_dim = 64  # number of features in the hidden state of the GRU\n",
    "num_layers = 1  # number of stacked GRU layers\n",
    "output_dim = 1  # single predicted price value\n",
    "\n",
    "# Create the model instance\n",
    "djia_price_model = DJIAPricePredictionModel(input_dim, hidden_dim, num_layers, output_dim)\n",
    "djia_price_model\n",
    "\n",
    "# Note: This model assumes that the historical prices and news sentiment scores are preprocessed and provided as inputs to the model. The sentiment scores should be derived using a lexicon-based method like SentiWordNet before being passed to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af3bf5e4-8a77-4062-8bef-d6516ccc1883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinBERTPricePredictionModel(\n",
       "  (gru): GRU(2, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FinBERTPricePredictionModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, output_dim):\n",
    "        super(FinBERTPricePredictionModel, self).__init__()\n",
    "        \n",
    "        # Since FinBERT already provides a sentiment score, there is no need for an embedding layer here.\n",
    "        \n",
    "        # GRU layer\n",
    "        self.gru = nn.GRU(input_size=2, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Linear layer that maps from hidden state space to price prediction space\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, last_price, sentiment_score):\n",
    "        # Concatenate last price and sentiment score along feature dimension\n",
    "        combined_input = torch.cat((last_price.unsqueeze(-1), sentiment_score.unsqueeze(-1)), dim=2)\n",
    "\n",
    "        # Passing in the input to the GRU and obtaining outputs\n",
    "        gru_out, _ = self.gru(combined_input)\n",
    "        \n",
    "        # Taking the last time step's output for the final price prediction\n",
    "        last_step_output = gru_out[:, -1, :]\n",
    "        \n",
    "        # Passing the last time step's output to the linear layer\n",
    "        price_prediction = self.fc(last_step_output)\n",
    "        return price_prediction\n",
    "\n",
    "# Parameters for the model\n",
    "hidden_dim = 64  # number of features in the hidden state of the GRU\n",
    "num_layers = 1  # number of stacked GRU layers\n",
    "output_dim = 1  # single predicted price value\n",
    "\n",
    "# Create the model instance\n",
    "finbert_price_model = FinBERTPricePredictionModel(hidden_dim, num_layers, output_dim)\n",
    "finbert_price_model\n",
    "\n",
    "# Note: This model assumes that the last price and sentiment score from FinBERT are preprocessed and provided as inputs to the model. The sentiment score should be encoded as a number between 0 and 1, where 0 could represent negative sentiment and 1 could represent positive sentiment. Neutral sentiment can be represented by a value in the middle, such as 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7adcb05d-2d13-4f10-bfd6-1a80a97cd1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalPricePredictionModel(\n",
       "  (gru_final): GRU(3, 64, batch_first=True)\n",
       "  (fc_final): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (ts_model): TimeSeriesGRU(\n",
       "    (gru_ts): GRU(1, 64, batch_first=True)\n",
       "    (fc_ts): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TimeSeriesGRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(TimeSeriesGRU, self).__init__()\n",
    "        \n",
    "        # GRU layer for time series prediction based only on historical data\n",
    "        self.gru_ts = nn.GRU(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Linear layer for time series prediction\n",
    "        self.fc_ts = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, historical_data):\n",
    "        # GRU for time series\n",
    "        gru_out_ts, _ = self.gru_ts(historical_data)\n",
    "        last_step_output_ts = gru_out_ts[:, -1, :]\n",
    "        predicted_price_ts = self.fc_ts(last_step_output_ts)\n",
    "        \n",
    "        return predicted_price_ts\n",
    "\n",
    "class FinalPricePredictionModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, output_dim):\n",
    "        super(FinalPricePredictionModel, self).__init__()\n",
    "        \n",
    "        # GRU layer for final prediction using past price, sentiment score, and predicted price\n",
    "        self.gru_final = nn.GRU(input_size=3, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Linear layer for final prediction\n",
    "        self.fc_final = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Time series GRU model for initial price prediction based on historical data\n",
    "        self.ts_model = TimeSeriesGRU(input_dim=1, hidden_dim=hidden_dim, num_layers=num_layers, output_dim=output_dim)\n",
    "\n",
    "    def forward(self, past_price, sentiment_score, historical_data):\n",
    "        # Get the time series predicted price\n",
    "        predicted_price_ts = self.ts_model(historical_data)\n",
    "\n",
    "        # Concatenate past price, sentiment score, and time series predicted price along feature dimension\n",
    "        combined_input = torch.cat((past_price.unsqueeze(-1), sentiment_score.unsqueeze(-1), predicted_price_ts.unsqueeze(-1)), dim=2)\n",
    "\n",
    "        # GRU for final prediction\n",
    "        gru_out_final, _ = self.gru_final(combined_input)\n",
    "        last_step_output_final = gru_out_final[:, -1, :]\n",
    "        final_predicted_price = self.fc_final(last_step_output_final)\n",
    "        \n",
    "        return final_predicted_price\n",
    "\n",
    "# Parameters for the model\n",
    "hidden_dim = 64  # number of features in the hidden state of the GRU\n",
    "num_layers = 1  # number of stacked GRU layers\n",
    "output_dim = 1  # single predicted price value\n",
    "\n",
    "# Create the model instance\n",
    "final_price_model = FinalPricePredictionModel(hidden_dim, num_layers, output_dim)\n",
    "final_price_model\n",
    "\n",
    "# Note: This model assumes that the past price, sentiment score, and historical data are preprocessed and provided as inputs to the model. The historical data should be a sequence of past prices used to predict the initial time-series based price prediction. Then, this initial prediction is combined with the past price and sentiment score for the final price prediction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
