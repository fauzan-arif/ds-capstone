{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53acfe4c-7237-409d-aa91-398f147da0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismaildibirov/Desktop/leidseplein folder/SPICED/ds-capstone/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ismaildibirov/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ismaildibirov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc2b803-89e3-4273-987f-90cdb0905c25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>658018b5112383a507ac9074</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>It's the Magnificent Seven's Market. The Other...</td>\n",
       "      <td>Apple, Microsoft, Alphabet, Amazon, Nvidia, Te...</td>\n",
       "      <td>Sun, 17 Dec 2023 07:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>658018b5112383a507ac9075</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>Buy Now, Pay Later Keeps People Spending---Wit...</td>\n",
       "      <td>Consumers are flocking to installment loans fo...</td>\n",
       "      <td>Sun, 17 Dec 2023 07:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>658018b5112383a507ac9076</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>How to Make the Most of Your FSA Money Before ...</td>\n",
       "      <td>Many workers take advantage of the tax-free fl...</td>\n",
       "      <td>Sat, 16 Dec 2023 21:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658018b5112383a507ac9077</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>Why It's Taking So Long for Americans to Get P...</td>\n",
       "      <td>Hundreds of banks use Fed’s new instant-paymen...</td>\n",
       "      <td>Sat, 16 Dec 2023 10:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658018b5112383a507ac9078</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>Robinhood Woos Wealthier Clients From Bigger B...</td>\n",
       "      <td>Known for a clientele of first-time investors,...</td>\n",
       "      <td>Sat, 16 Dec 2023 10:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>658018b5112383a507ac9079</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>Tesla's Self-Driving Tech Has Competition</td>\n",
       "      <td>Gradually improving driver-assistance features...</td>\n",
       "      <td>Sat, 16 Dec 2023 10:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>658018b5112383a507ac907a</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>The Score: Macy's, Hasbro, Pfizer and More Sto...</td>\n",
       "      <td>Here are some of the major companies whose sto...</td>\n",
       "      <td>Fri, 15 Dec 2023 18:16:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>658018b5112383a507ac907b</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>Beware the Most Crowded Trade on Wall Street: ...</td>\n",
       "      <td>Each of the past three years had a similarly s...</td>\n",
       "      <td>Fri, 15 Dec 2023 16:54:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>658018b5112383a507ac907c</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>Visa Agrees to Acquire Majority Interest in Pa...</td>\n",
       "      <td>Visa entered into an agreement to acquire a ma...</td>\n",
       "      <td>Fri, 15 Dec 2023 16:36:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>658018b6112383a507ac907d</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>Dow Notches Another Record Close</td>\n",
       "      <td>The blue-chip index notched its third straight...</td>\n",
       "      <td>Fri, 15 Dec 2023 16:33:00 -0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id           channel  \\\n",
       "0  658018b5112383a507ac9074  WSJ.com: Markets   \n",
       "1  658018b5112383a507ac9075  WSJ.com: Markets   \n",
       "2  658018b5112383a507ac9076  WSJ.com: Markets   \n",
       "3  658018b5112383a507ac9077  WSJ.com: Markets   \n",
       "4  658018b5112383a507ac9078  WSJ.com: Markets   \n",
       "5  658018b5112383a507ac9079  WSJ.com: Markets   \n",
       "6  658018b5112383a507ac907a  WSJ.com: Markets   \n",
       "7  658018b5112383a507ac907b  WSJ.com: Markets   \n",
       "8  658018b5112383a507ac907c  WSJ.com: Markets   \n",
       "9  658018b6112383a507ac907d  WSJ.com: Markets   \n",
       "\n",
       "                                               title  \\\n",
       "0  It's the Magnificent Seven's Market. The Other...   \n",
       "1  Buy Now, Pay Later Keeps People Spending---Wit...   \n",
       "2  How to Make the Most of Your FSA Money Before ...   \n",
       "3  Why It's Taking So Long for Americans to Get P...   \n",
       "4  Robinhood Woos Wealthier Clients From Bigger B...   \n",
       "5          Tesla's Self-Driving Tech Has Competition   \n",
       "6  The Score: Macy's, Hasbro, Pfizer and More Sto...   \n",
       "7  Beware the Most Crowded Trade on Wall Street: ...   \n",
       "8  Visa Agrees to Acquire Majority Interest in Pa...   \n",
       "9                   Dow Notches Another Record Close   \n",
       "\n",
       "                                                text  \\\n",
       "0  Apple, Microsoft, Alphabet, Amazon, Nvidia, Te...   \n",
       "1  Consumers are flocking to installment loans fo...   \n",
       "2  Many workers take advantage of the tax-free fl...   \n",
       "3  Hundreds of banks use Fed’s new instant-paymen...   \n",
       "4  Known for a clientele of first-time investors,...   \n",
       "5  Gradually improving driver-assistance features...   \n",
       "6  Here are some of the major companies whose sto...   \n",
       "7  Each of the past three years had a similarly s...   \n",
       "8  Visa entered into an agreement to acquire a ma...   \n",
       "9  The blue-chip index notched its third straight...   \n",
       "\n",
       "                              date  \n",
       "0  Sun, 17 Dec 2023 07:00:00 -0500  \n",
       "1  Sun, 17 Dec 2023 07:00:00 -0500  \n",
       "2  Sat, 16 Dec 2023 21:00:00 -0500  \n",
       "3  Sat, 16 Dec 2023 10:00:00 -0500  \n",
       "4  Sat, 16 Dec 2023 10:00:00 -0500  \n",
       "5  Sat, 16 Dec 2023 10:00:00 -0500  \n",
       "6  Fri, 15 Dec 2023 18:16:00 -0500  \n",
       "7  Fri, 15 Dec 2023 16:54:00 -0500  \n",
       "8  Fri, 15 Dec 2023 16:36:00 -0500  \n",
       "9  Fri, 15 Dec 2023 16:33:00 -0500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/rss_fin.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4b70eb-f995-4727-a114-2c420e98bd5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 615 entries, 0 to 614\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   _id      615 non-null    object\n",
      " 1   channel  605 non-null    object\n",
      " 2   title    615 non-null    object\n",
      " 3   text     604 non-null    object\n",
      " 4   date     615 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 24.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26de65-6fac-41e8-ad8d-604123f482ea",
   "metadata": {},
   "source": [
    "### Data Cleaning, Tokenization & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdd8cbfd-08d9-484d-9cfd-7e7aba0eb45e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Apply spaCy to tokenize and lemmatize the text\n",
    "    doc = nlp(text.lower())\n",
    "    \n",
    "    # Extract tokens that are not stop words and are not punctuations\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    processed_text = \" \".join(tokens)\n",
    "    \n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b589d02-f2f1-4e9a-bcfa-6c0a7e751f23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.dropna(subset=['title', 'text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03dfed19-66e2-40ce-939e-078fee503cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>658018b5112383a507ac9074</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>magnificent seven market stock live</td>\n",
       "      <td>apple microsoft alphabet amazon nvidia tesla m...</td>\n",
       "      <td>Sun, 17 Dec 2023 07:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>658018b5112383a507ac9075</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>buy pay later people spend credit agency know</td>\n",
       "      <td>consumer flock installment loan holiday gift g...</td>\n",
       "      <td>Sun, 17 Dec 2023 07:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>658018b5112383a507ac9076</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>fsa money disappear</td>\n",
       "      <td>worker advantage tax free flexible spend accou...</td>\n",
       "      <td>Sat, 16 Dec 2023 21:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658018b5112383a507ac9077</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>long americans payment instantly</td>\n",
       "      <td>bank use feed new instant payment service univ...</td>\n",
       "      <td>Sat, 16 Dec 2023 10:00:00 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658018b5112383a507ac9078</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>robinhood woo wealthy client big brokerage</td>\n",
       "      <td>know clientele time investor trading app recei...</td>\n",
       "      <td>Sat, 16 Dec 2023 10:00:00 -0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id           channel  \\\n",
       "0  658018b5112383a507ac9074  WSJ.com: Markets   \n",
       "1  658018b5112383a507ac9075  WSJ.com: Markets   \n",
       "2  658018b5112383a507ac9076  WSJ.com: Markets   \n",
       "3  658018b5112383a507ac9077  WSJ.com: Markets   \n",
       "4  658018b5112383a507ac9078  WSJ.com: Markets   \n",
       "\n",
       "                                           title  \\\n",
       "0            magnificent seven market stock live   \n",
       "1  buy pay later people spend credit agency know   \n",
       "2                            fsa money disappear   \n",
       "3               long americans payment instantly   \n",
       "4     robinhood woo wealthy client big brokerage   \n",
       "\n",
       "                                                text  \\\n",
       "0  apple microsoft alphabet amazon nvidia tesla m...   \n",
       "1  consumer flock installment loan holiday gift g...   \n",
       "2  worker advantage tax free flexible spend accou...   \n",
       "3  bank use feed new instant payment service univ...   \n",
       "4  know clientele time investor trading app recei...   \n",
       "\n",
       "                              date  \n",
       "0  Sun, 17 Dec 2023 07:00:00 -0500  \n",
       "1  Sun, 17 Dec 2023 07:00:00 -0500  \n",
       "2  Sat, 16 Dec 2023 21:00:00 -0500  \n",
       "3  Sat, 16 Dec 2023 10:00:00 -0500  \n",
       "4  Sat, 16 Dec 2023 10:00:00 -0500  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the process_text function to the 'text' and 'title' columns\n",
    "data['text'] = data['text'].apply(process_text)\n",
    "data['title'] = data['title'].apply(process_text)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f02b400-8213-424b-b253-800344ad720b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_glove_vectors(text):\n",
    "    # Apply spaCy to tokenize and get GloVe word vectors\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract the GloVe vectors for each token in the text\n",
    "    vectors = [token.vector for token in doc]\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b438084d-732e-4ef3-bd61-3e1739589c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>text_vectors</th>\n",
       "      <th>title_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>658018b5112383a507ac9074</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>magnificent seven market stock live</td>\n",
       "      <td>apple microsoft alphabet amazon nvidia tesla m...</td>\n",
       "      <td>Sun, 17 Dec 2023 07:00:00 -0500</td>\n",
       "      <td>[[-0.18625039, -0.8668952, 0.046901673, 1.1034...</td>\n",
       "      <td>[[-0.9848044, -0.40753686, -0.089207575, 0.038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>658018b5112383a507ac9075</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>buy pay late people spend credit agency know</td>\n",
       "      <td>consumer flock installment loan holiday gift g...</td>\n",
       "      <td>Sun, 17 Dec 2023 07:00:00 -0500</td>\n",
       "      <td>[[-0.11025052, -0.30337343, 0.53082794, -0.281...</td>\n",
       "      <td>[[-0.84627914, -1.3933793, 1.4022795, 0.190420...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>658018b5112383a507ac9076</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>fsa money disappear</td>\n",
       "      <td>worker advantage tax free flexible spend accou...</td>\n",
       "      <td>Sat, 16 Dec 2023 21:00:00 -0500</td>\n",
       "      <td>[[-0.5689461, -0.6188227, -0.029612377, -0.167...</td>\n",
       "      <td>[[0.22389163, -1.1406136, 0.12869072, 0.897906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658018b5112383a507ac9077</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>long americans payment instantly</td>\n",
       "      <td>bank use feed new instant payment service univ...</td>\n",
       "      <td>Sat, 16 Dec 2023 10:00:00 -0500</td>\n",
       "      <td>[[-0.57085145, -1.6188182, 0.13059917, 0.21096...</td>\n",
       "      <td>[[-0.033791594, -1.0400614, 0.21256757, 1.9177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658018b5112383a507ac9078</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>robinhood woo wealthy client big brokerage</td>\n",
       "      <td>know clientele time investor trading app recei...</td>\n",
       "      <td>Sat, 16 Dec 2023 10:00:00 -0500</td>\n",
       "      <td>[[0.33517328, -2.3876314, 0.8566309, 0.6664783...</td>\n",
       "      <td>[[-0.76147354, -0.9745778, 0.6955986, 0.359618...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id           channel  \\\n",
       "0  658018b5112383a507ac9074  WSJ.com: Markets   \n",
       "1  658018b5112383a507ac9075  WSJ.com: Markets   \n",
       "2  658018b5112383a507ac9076  WSJ.com: Markets   \n",
       "3  658018b5112383a507ac9077  WSJ.com: Markets   \n",
       "4  658018b5112383a507ac9078  WSJ.com: Markets   \n",
       "\n",
       "                                          title  \\\n",
       "0           magnificent seven market stock live   \n",
       "1  buy pay late people spend credit agency know   \n",
       "2                           fsa money disappear   \n",
       "3              long americans payment instantly   \n",
       "4    robinhood woo wealthy client big brokerage   \n",
       "\n",
       "                                                text  \\\n",
       "0  apple microsoft alphabet amazon nvidia tesla m...   \n",
       "1  consumer flock installment loan holiday gift g...   \n",
       "2  worker advantage tax free flexible spend accou...   \n",
       "3  bank use feed new instant payment service univ...   \n",
       "4  know clientele time investor trading app recei...   \n",
       "\n",
       "                              date  \\\n",
       "0  Sun, 17 Dec 2023 07:00:00 -0500   \n",
       "1  Sun, 17 Dec 2023 07:00:00 -0500   \n",
       "2  Sat, 16 Dec 2023 21:00:00 -0500   \n",
       "3  Sat, 16 Dec 2023 10:00:00 -0500   \n",
       "4  Sat, 16 Dec 2023 10:00:00 -0500   \n",
       "\n",
       "                                        text_vectors  \\\n",
       "0  [[-0.18625039, -0.8668952, 0.046901673, 1.1034...   \n",
       "1  [[-0.11025052, -0.30337343, 0.53082794, -0.281...   \n",
       "2  [[-0.5689461, -0.6188227, -0.029612377, -0.167...   \n",
       "3  [[-0.57085145, -1.6188182, 0.13059917, 0.21096...   \n",
       "4  [[0.33517328, -2.3876314, 0.8566309, 0.6664783...   \n",
       "\n",
       "                                       title_vectors  \n",
       "0  [[-0.9848044, -0.40753686, -0.089207575, 0.038...  \n",
       "1  [[-0.84627914, -1.3933793, 1.4022795, 0.190420...  \n",
       "2  [[0.22389163, -1.1406136, 0.12869072, 0.897906...  \n",
       "3  [[-0.033791594, -1.0400614, 0.21256757, 1.9177...  \n",
       "4  [[-0.76147354, -0.9745778, 0.6955986, 0.359618...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the process_text and get_glove_vectors functions to the 'text' and 'title' columns\n",
    "data['text'] = data['text'].apply(process_text)\n",
    "data['title'] = data['title'].apply(process_text)\n",
    "data['text_vectors'] = data['text'].apply(get_glove_vectors)\n",
    "data['title_vectors'] = data['title'].apply(get_glove_vectors)\n",
    "\n",
    "# Display the processed DataFrame with GloVe word vectors\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b78089-f4ac-4801-a27d-8442c4fc2fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd497ca-4a10-46ec-8e9e-9c57f382840a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings_dict\n\u001b[0;32m---> 15\u001b[0m glove_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mload_glove_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m, in \u001b[0;36mload_glove_embeddings\u001b[0;34m(glove_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_glove_embeddings\u001b[39m(glove_file):\n\u001b[1;32m      2\u001b[0m     embeddings_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mglove_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m             values \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[0;32m~/Desktop/leidseplein folder/SPICED/ds-capstone/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:303\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(io_open)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_modified_open\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m}\u001b[49m:\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(glove_file):\n",
    "    embeddings_dict = {}\n",
    "    with open(glove_file, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            try:\n",
    "                vector = np.asarray(values[1:], \"float32\")\n",
    "                embeddings_dict[word] = vector\n",
    "            except ValueError:\n",
    "                print(f\"Error converting to float: {values[1:]} for word: {word}\")\n",
    "                continue\n",
    "    return embeddings_dict\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(\"../data/glove.840B.300d.txt\")  # replace with your GloVe file path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75668123-b82a-4204-8076-293936fdc25c",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0d3073-188c-4103-bd69-4d93b8d66bee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ismaildibirov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ismaildibirov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the list of stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    # Remove possessive endings\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words and convert to lower case\n",
    "    filtered_text = [word for word in tokens if word.lower() not in stop_words]\n",
    "    # Join the words back into a string\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "# Drop rows where either 'title' or 'text' is NaN\n",
    "data.dropna(subset=['title', 'text'], inplace=True)\n",
    "\n",
    "# Apply the stop words removal\n",
    "data['title'] = data['title'].apply(remove_stop_words)\n",
    "data['text'] = data['text'].apply(remove_stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9446eb9-0a65-4533-96b0-96afb1111718",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>658018b5112383a507ac9074</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>magnificent seven market . stock living .</td>\n",
       "      <td>apple , microsoft , alphabet , amazon , nvidia...</td>\n",
       "      <td>Sun, 17 Dec 2023 07:00:00 -0500</td>\n",
       "      <td>[It, 's, the, Magnificent, Seven, 's, Market, ...</td>\n",
       "      <td>[Apple, ,, Microsoft, ,, Alphabet, ,, Amazon, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>658018b5112383a507ac9075</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>buy , pay later keep people spending -- -witho...</td>\n",
       "      <td>consumer flocking installment loan everything ...</td>\n",
       "      <td>Sun, 17 Dec 2023 07:00:00 -0500</td>\n",
       "      <td>[Buy, Now, ,, Pay, Later, Keeps, People, Spend...</td>\n",
       "      <td>[Consumers, are, flocking, to, installment, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>658018b5112383a507ac9076</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>make fsa money disappears</td>\n",
       "      <td>many worker take advantage tax-free flexible-s...</td>\n",
       "      <td>Sat, 16 Dec 2023 21:00:00 -0500</td>\n",
       "      <td>[How, to, Make, the, Most, of, Your, FSA, Mone...</td>\n",
       "      <td>[Many, workers, take, advantage, of, the, tax-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658018b5112383a507ac9077</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>taking long american get payment instantly</td>\n",
       "      <td>hundred bank use fed ’ new instant-payment ser...</td>\n",
       "      <td>Sat, 16 Dec 2023 10:00:00 -0500</td>\n",
       "      <td>[Why, It, 's, Taking, So, Long, for, Americans...</td>\n",
       "      <td>[Hundreds, of, banks, use, Fed, ’, s, new, ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658018b5112383a507ac9078</td>\n",
       "      <td>WSJ.com: Markets</td>\n",
       "      <td>robinhood woos wealthier client bigger brokerage</td>\n",
       "      <td>known clientele first-time investor , trading ...</td>\n",
       "      <td>Sat, 16 Dec 2023 10:00:00 -0500</td>\n",
       "      <td>[Robinhood, Woos, Wealthier, Clients, From, Bi...</td>\n",
       "      <td>[Known, for, a, clientele, of, first-time, inv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id           channel  \\\n",
       "0  658018b5112383a507ac9074  WSJ.com: Markets   \n",
       "1  658018b5112383a507ac9075  WSJ.com: Markets   \n",
       "2  658018b5112383a507ac9076  WSJ.com: Markets   \n",
       "3  658018b5112383a507ac9077  WSJ.com: Markets   \n",
       "4  658018b5112383a507ac9078  WSJ.com: Markets   \n",
       "\n",
       "                                               title  \\\n",
       "0          magnificent seven market . stock living .   \n",
       "1  buy , pay later keep people spending -- -witho...   \n",
       "2                          make fsa money disappears   \n",
       "3         taking long american get payment instantly   \n",
       "4   robinhood woos wealthier client bigger brokerage   \n",
       "\n",
       "                                                text  \\\n",
       "0  apple , microsoft , alphabet , amazon , nvidia...   \n",
       "1  consumer flocking installment loan everything ...   \n",
       "2  many worker take advantage tax-free flexible-s...   \n",
       "3  hundred bank use fed ’ new instant-payment ser...   \n",
       "4  known clientele first-time investor , trading ...   \n",
       "\n",
       "                              date  \\\n",
       "0  Sun, 17 Dec 2023 07:00:00 -0500   \n",
       "1  Sun, 17 Dec 2023 07:00:00 -0500   \n",
       "2  Sat, 16 Dec 2023 21:00:00 -0500   \n",
       "3  Sat, 16 Dec 2023 10:00:00 -0500   \n",
       "4  Sat, 16 Dec 2023 10:00:00 -0500   \n",
       "\n",
       "                                     tokenized_title  \\\n",
       "0  [It, 's, the, Magnificent, Seven, 's, Market, ...   \n",
       "1  [Buy, Now, ,, Pay, Later, Keeps, People, Spend...   \n",
       "2  [How, to, Make, the, Most, of, Your, FSA, Mone...   \n",
       "3  [Why, It, 's, Taking, So, Long, for, Americans...   \n",
       "4  [Robinhood, Woos, Wealthier, Clients, From, Bi...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [Apple, ,, Microsoft, ,, Alphabet, ,, Amazon, ...  \n",
       "1  [Consumers, are, flocking, to, installment, lo...  \n",
       "2  [Many, workers, take, advantage, of, the, tax-...  \n",
       "3  [Hundreds, of, banks, use, Fed, ’, s, new, ins...  \n",
       "4  [Known, for, a, clientele, of, first-time, inv...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203520ac-1d86-4226-8aa9-06b7b45c762f",
   "metadata": {},
   "source": [
    "### Sentiment Analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b62080d4-863a-47d1-993a-7cdcefcf9723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SentimentCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_filters, filter_sizes, output_dim=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc1 = nn.Linear(len(filter_sizes) * num_filters, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [batch size, sent len, emb dim]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # x = [batch size, emb dim, sent len]\n",
    "        x = [F.relu(conv(x)) for conv in self.convs]\n",
    "        x = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in x]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "# Example usage\n",
    "model = SentimentCNN(embedding_dim=100, num_filters=100, filter_sizes=[3, 4, 5], dropout=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f49089b-42c2-4e16-acd9-68737e41fce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m input_text \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a positive sentence.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a neutral sentence.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a negative sentence.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Tokenize and preprocess your input text (replace with your preprocessing code)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# You need to convert the text into numerical embeddings.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Convert input_data to a tensor (assuming it's already properly formatted)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m input_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[43minput_data\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Pass the data through the model to get sentiment outputs\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_data' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example text data (replace with your actual data)\n",
    "input_text = data[\"]\n",
    "\n",
    "# Tokenize and preprocess your input text (replace with your preprocessing code)\n",
    "# You need to convert the text into numerical embeddings.\n",
    "\n",
    "# For example, assuming you have a function preprocess_text(text) that converts text to embeddings:\n",
    "# input_data = [preprocess_text(text) for text in input_text]\n",
    "\n",
    "# Convert input_data to a tensor (assuming it's already properly formatted)\n",
    "input_data = torch.Tensor(input_data)\n",
    "\n",
    "# Pass the data through the model to get sentiment outputs\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    sentiment_outputs = model(input_data)\n",
    "\n",
    "# sentiment_outputs is a tensor containing the sentiment predictions for each input sentence\n",
    "# You can now work with sentiment_outputs as needed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
