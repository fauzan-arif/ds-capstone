{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53acfe4c-7237-409d-aa91-398f147da0de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/kevinmelchert/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc2b803-89e3-4273-987f-90cdb0905c25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>channel._id</th>\n",
       "      <th>channel.name</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6579c6139c8c4517bf26e14e</td>\n",
       "      <td>65784dec2d93a25348d0ab85</td>\n",
       "      <td>cryptowhalesreal</td>\n",
       "      <td>I hope eveyone could get this fabulous profit ...</td>\n",
       "      <td>2023-12-12T09:40:12.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6579c6149c8c4517bf26e14f</td>\n",
       "      <td>65784dec2d93a25348d0ab85</td>\n",
       "      <td>cryptowhalesreal</td>\n",
       "      <td>üéÅ #FREE_SIGNAL \\n\\nüü£ Future Signal üü£\\nüìà BUY\\n‚ùá...</td>\n",
       "      <td>2023-12-11T12:39:33.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id               channel._id      channel.name  \\\n",
       "0  6579c6139c8c4517bf26e14e  65784dec2d93a25348d0ab85  cryptowhalesreal   \n",
       "1  6579c6149c8c4517bf26e14f  65784dec2d93a25348d0ab85  cryptowhalesreal   \n",
       "\n",
       "                                                text                      date  \n",
       "0  I hope eveyone could get this fabulous profit ...  2023-12-12T09:40:12.000Z  \n",
       "1  üéÅ #FREE_SIGNAL \\n\\nüü£ Future Signal üü£\\nüìà BUY\\n‚ùá...  2023-12-11T12:39:33.000Z  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/capstone.messages.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0393c1a-c0a8-49d6-9f0e-8b7d52628c70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>_id</th>\n",
       "      <th>channel._id</th>\n",
       "      <th>channel.name</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6579c6139c8c4517bf26e14e</td>\n",
       "      <td>65784dec2d93a25348d0ab85</td>\n",
       "      <td>cryptowhalesreal</td>\n",
       "      <td>I hope eveyone could get this fabulous profit ...</td>\n",
       "      <td>2023-12-12T09:40:12.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6579c6149c8c4517bf26e14f</td>\n",
       "      <td>65784dec2d93a25348d0ab85</td>\n",
       "      <td>cryptowhalesreal</td>\n",
       "      <td>üéÅ #FREE_SIGNAL \\n\\nüü£ Future Signal üü£\\nüìà BUY\\n‚ùá...</td>\n",
       "      <td>2023-12-11T12:39:33.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6579c6149c8c4517bf26e150</td>\n",
       "      <td>65784dec2d93a25348d0ab85</td>\n",
       "      <td>cryptowhalesreal</td>\n",
       "      <td>Another 40% profit after the entry for a buy s...</td>\n",
       "      <td>2023-12-10T13:24:29.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6579c6149c8c4517bf26e151</td>\n",
       "      <td>65784dec2d93a25348d0ab85</td>\n",
       "      <td>cryptowhalesreal</td>\n",
       "      <td>üü£ Future Signal üü£\\nüìà BUY\\n‚ùáÔ∏è #SOL - USDT\\nüè¢ Ex...</td>\n",
       "      <td>2023-12-10T13:24:20.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6579c6149c8c4517bf26e152</td>\n",
       "      <td>65784dec2d93a25348d0ab85</td>\n",
       "      <td>cryptowhalesreal</td>\n",
       "      <td>This is the correct way of starting the weeken...</td>\n",
       "      <td>2023-12-09T07:54:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5696</th>\n",
       "      <td>5778</td>\n",
       "      <td>6579c6b99c8c4517bf26f7e0</td>\n",
       "      <td>657982e5660a918f6a6e4b70</td>\n",
       "      <td>cryptotipstrick</td>\n",
       "      <td>‚ö°Ô∏è‚ö°Ô∏è #WOO/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Future...</td>\n",
       "      <td>2023-11-16T15:42:24.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>5779</td>\n",
       "      <td>6579c6b99c8c4517bf26f7e1</td>\n",
       "      <td>657982e5660a918f6a6e4b70</td>\n",
       "      <td>cryptotipstrick</td>\n",
       "      <td>‚ö°Ô∏è‚ö°Ô∏è #SNX/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Future...</td>\n",
       "      <td>2023-11-16T15:42:09.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>5780</td>\n",
       "      <td>6579c6b99c8c4517bf26f7e2</td>\n",
       "      <td>657982e5660a918f6a6e4b70</td>\n",
       "      <td>cryptotipstrick</td>\n",
       "      <td>‚ö°Ô∏è‚ö°Ô∏è #RNDR/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Futur...</td>\n",
       "      <td>2023-11-16T15:41:51.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5699</th>\n",
       "      <td>5781</td>\n",
       "      <td>6579c6b99c8c4517bf26f7e3</td>\n",
       "      <td>657982e5660a918f6a6e4b70</td>\n",
       "      <td>cryptotipstrick</td>\n",
       "      <td>‚ö°Ô∏è‚ö°Ô∏è #RNDR/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Futur...</td>\n",
       "      <td>2023-11-16T15:41:50.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5700</th>\n",
       "      <td>5782</td>\n",
       "      <td>6579c6b99c8c4517bf26f7e4</td>\n",
       "      <td>657982e5660a918f6a6e4b70</td>\n",
       "      <td>cryptotipstrick</td>\n",
       "      <td>‚ö°Ô∏è‚ö°Ô∏è #DASH/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Futur...</td>\n",
       "      <td>2023-11-16T10:40:22.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5701 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                       _id               channel._id  \\\n",
       "0         0  6579c6139c8c4517bf26e14e  65784dec2d93a25348d0ab85   \n",
       "1         1  6579c6149c8c4517bf26e14f  65784dec2d93a25348d0ab85   \n",
       "2         2  6579c6149c8c4517bf26e150  65784dec2d93a25348d0ab85   \n",
       "3         3  6579c6149c8c4517bf26e151  65784dec2d93a25348d0ab85   \n",
       "4         4  6579c6149c8c4517bf26e152  65784dec2d93a25348d0ab85   \n",
       "...     ...                       ...                       ...   \n",
       "5696   5778  6579c6b99c8c4517bf26f7e0  657982e5660a918f6a6e4b70   \n",
       "5697   5779  6579c6b99c8c4517bf26f7e1  657982e5660a918f6a6e4b70   \n",
       "5698   5780  6579c6b99c8c4517bf26f7e2  657982e5660a918f6a6e4b70   \n",
       "5699   5781  6579c6b99c8c4517bf26f7e3  657982e5660a918f6a6e4b70   \n",
       "5700   5782  6579c6b99c8c4517bf26f7e4  657982e5660a918f6a6e4b70   \n",
       "\n",
       "          channel.name                                               text  \\\n",
       "0     cryptowhalesreal  I hope eveyone could get this fabulous profit ...   \n",
       "1     cryptowhalesreal  üéÅ #FREE_SIGNAL \\n\\nüü£ Future Signal üü£\\nüìà BUY\\n‚ùá...   \n",
       "2     cryptowhalesreal  Another 40% profit after the entry for a buy s...   \n",
       "3     cryptowhalesreal  üü£ Future Signal üü£\\nüìà BUY\\n‚ùáÔ∏è #SOL - USDT\\nüè¢ Ex...   \n",
       "4     cryptowhalesreal  This is the correct way of starting the weeken...   \n",
       "...                ...                                                ...   \n",
       "5696   cryptotipstrick  ‚ö°Ô∏è‚ö°Ô∏è #WOO/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Future...   \n",
       "5697   cryptotipstrick  ‚ö°Ô∏è‚ö°Ô∏è #SNX/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Future...   \n",
       "5698   cryptotipstrick  ‚ö°Ô∏è‚ö°Ô∏è #RNDR/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Futur...   \n",
       "5699   cryptotipstrick  ‚ö°Ô∏è‚ö°Ô∏è #RNDR/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Futur...   \n",
       "5700   cryptotipstrick  ‚ö°Ô∏è‚ö°Ô∏è #DASH/USDT ‚ö°Ô∏è‚ö°Ô∏è\\nExchanges: Binance Futur...   \n",
       "\n",
       "                          date  \n",
       "0     2023-12-12T09:40:12.000Z  \n",
       "1     2023-12-11T12:39:33.000Z  \n",
       "2     2023-12-10T13:24:29.000Z  \n",
       "3     2023-12-10T13:24:20.000Z  \n",
       "4     2023-12-09T07:54:00.000Z  \n",
       "...                        ...  \n",
       "5696  2023-11-16T15:42:24.000Z  \n",
       "5697  2023-11-16T15:42:09.000Z  \n",
       "5698  2023-11-16T15:41:51.000Z  \n",
       "5699  2023-11-16T15:41:50.000Z  \n",
       "5700  2023-11-16T10:40:22.000Z  \n",
       "\n",
       "[5701 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing empty rows\n",
    "data = data[data.text.notna()]\n",
    "data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd8cbfd-08d9-484d-9cfd-7e7aba0eb45e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hope eveyone could get this fabulous profit ...</td>\n",
       "      <td>i hope eveyone could get this fabulous profit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üéÅ #FREE_SIGNAL \\n\\nüü£ Future Signal üü£\\nüìà BUY\\n‚ùá...</td>\n",
       "      <td>free signal future signal buy tia usdt exchan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Another 40% profit after the entry for a buy s...</td>\n",
       "      <td>another 40% profit after the entry for a buy s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üü£ Future Signal üü£\\nüìà BUY\\n‚ùáÔ∏è #SOL - USDT\\nüè¢ Ex...</td>\n",
       "      <td>future signal buy sol usdt exchange all avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the correct way of starting the weeken...</td>\n",
       "      <td>this is the correct way of starting the weeken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>üü£ Future Signal üü£\\nüìà BUY\\n‚ùáÔ∏è #SXP - USDT\\nüè¢ Ex...</td>\n",
       "      <td>future signal buy sxp usdt exchange all avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Semms #YGG doen't have enough strength. We jus...</td>\n",
       "      <td>semms ygg doen t have enough strength we just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The price had a bearish shadow; don't worry üòÆ‚Äç...</td>\n",
       "      <td>the price had a bearish shadow don t worry nti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>üéÅ #FREE_SIGNAL \\n\\nüü£ Future Signal üü£\\nüìà BUY\\n‚ùá...</td>\n",
       "      <td>free signal future signal buy ygg usdt exchan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We keep the Monday Blues away with profitable ...</td>\n",
       "      <td>we keep the monday blues away with profitable ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I hope eveyone could get this fabulous profit ...   \n",
       "1  üéÅ #FREE_SIGNAL \\n\\nüü£ Future Signal üü£\\nüìà BUY\\n‚ùá...   \n",
       "2  Another 40% profit after the entry for a buy s...   \n",
       "3  üü£ Future Signal üü£\\nüìà BUY\\n‚ùáÔ∏è #SOL - USDT\\nüè¢ Ex...   \n",
       "4  This is the correct way of starting the weeken...   \n",
       "5  üü£ Future Signal üü£\\nüìà BUY\\n‚ùáÔ∏è #SXP - USDT\\nüè¢ Ex...   \n",
       "6  Semms #YGG doen't have enough strength. We jus...   \n",
       "7  The price had a bearish shadow; don't worry üòÆ‚Äç...   \n",
       "8  üéÅ #FREE_SIGNAL \\n\\nüü£ Future Signal üü£\\nüìà BUY\\n‚ùá...   \n",
       "9  We keep the Monday Blues away with profitable ...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  i hope eveyone could get this fabulous profit ...  \n",
       "1   free signal future signal buy tia usdt exchan...  \n",
       "2  another 40% profit after the entry for a buy s...  \n",
       "3   future signal buy sol usdt exchange all avail...  \n",
       "4  this is the correct way of starting the weeken...  \n",
       "5   future signal buy sxp usdt exchange all avail...  \n",
       "6  semms ygg doen t have enough strength we just ...  \n",
       "7  the price had a bearish shadow don t worry nti...  \n",
       "8   free signal future signal buy ygg usdt exchan...  \n",
       "9  we keep the monday blues away with profitable ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correcting the function to effectively remove all hanging 'n's\n",
    "def clean_text_final_corrected(text):\n",
    "    # Removing line breaks and replacing with space\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Removing any standalone 'n' characters that might have been left from '\\n'\n",
    "    text = re.sub(r'\\b[n]\\b', ' ', text)\n",
    "    # Remaining cleaning steps\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9%$]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Removing extra space\n",
    "    return text.lower()\n",
    "\n",
    "# Reapplying the corrected text cleaning function\n",
    "data['cleaned_text'] = data['text'].apply(clean_text_final_corrected)\n",
    "\n",
    "# Displaying the first few rows of the updated cleaned data\n",
    "data[['text', 'cleaned_text']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e4ff88-9305-41f3-9651-20d6271683d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>manual_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i hope eveyone could get this fabulous profit ...</td>\n",
       "      <td>[i, hope, eveyone, could, get, this, fabulous,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>free signal future signal buy tia usdt exchan...</td>\n",
       "      <td>[free, signal, future, signal, buy, tia, usdt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>another 40% profit after the entry for a buy s...</td>\n",
       "      <td>[another, 40%, profit, after, the, entry, for,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>future signal buy sol usdt exchange all avail...</td>\n",
       "      <td>[future, signal, buy, sol, usdt, exchange, all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is the correct way of starting the weeken...</td>\n",
       "      <td>[this, is, the, correct, way, of, starting, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  \\\n",
       "0  i hope eveyone could get this fabulous profit ...   \n",
       "1   free signal future signal buy tia usdt exchan...   \n",
       "2  another 40% profit after the entry for a buy s...   \n",
       "3   future signal buy sol usdt exchange all avail...   \n",
       "4  this is the correct way of starting the weeken...   \n",
       "\n",
       "                                       manual_tokens  \n",
       "0  [i, hope, eveyone, could, get, this, fabulous,...  \n",
       "1  [free, signal, future, signal, buy, tia, usdt,...  \n",
       "2  [another, 40%, profit, after, the, entry, for,...  \n",
       "3  [future, signal, buy, sol, usdt, exchange, all...  \n",
       "4  [this, is, the, correct, way, of, starting, th...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual tokenization function\n",
    "def manual_tokenize(text):\n",
    "    # Simple tokenization by splitting on spaces (this is less sophisticated than NLTK's word_tokenize)\n",
    "    return text.split()\n",
    "\n",
    "# Applying manual tokenization to the cleaned text\n",
    "data['manual_tokens'] = data['cleaned_text'].apply(manual_tokenize)\n",
    "\n",
    "# Displaying the first few rows with manual tokens\n",
    "data[['cleaned_text', 'manual_tokens']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781b3002-ff6c-4af0-8167-fd23f2ee54cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manual_tokens</th>\n",
       "      <th>tokens_no_stopwords_manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, hope, eveyone, could, get, this, fabulous,...</td>\n",
       "      <td>[hope, eveyone, could, get, fabulous, profit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[free, signal, future, signal, buy, tia, usdt,...</td>\n",
       "      <td>[free, signal, future, signal, buy, tia, usdt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[another, 40%, profit, after, the, entry, for,...</td>\n",
       "      <td>[another, 40%, profit, entry, buy, signal, cry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[future, signal, buy, sol, usdt, exchange, all...</td>\n",
       "      <td>[future, signal, buy, sol, usdt, exchange, ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[this, is, the, correct, way, of, starting, th...</td>\n",
       "      <td>[correct, way, starting, weekend, ntouched, ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       manual_tokens  \\\n",
       "0  [i, hope, eveyone, could, get, this, fabulous,...   \n",
       "1  [free, signal, future, signal, buy, tia, usdt,...   \n",
       "2  [another, 40%, profit, after, the, entry, for,...   \n",
       "3  [future, signal, buy, sol, usdt, exchange, all...   \n",
       "4  [this, is, the, correct, way, of, starting, th...   \n",
       "\n",
       "                          tokens_no_stopwords_manual  \n",
       "0  [hope, eveyone, could, get, fabulous, profit, ...  \n",
       "1  [free, signal, future, signal, buy, tia, usdt,...  \n",
       "2  [another, 40%, profit, entry, buy, signal, cry...  \n",
       "3  [future, signal, buy, sol, usdt, exchange, ava...  \n",
       "4  [correct, way, starting, weekend, ntouched, ta...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually defining a basic list of English stopwords\n",
    "basic_stopwords = set([\n",
    "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \n",
    "    \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \n",
    "    \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \n",
    "    \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \n",
    "    \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \n",
    "    \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \n",
    "    \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \n",
    "    \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \n",
    "    \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \n",
    "    \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \n",
    "    \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \n",
    "    \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \n",
    "    \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \n",
    "    \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"\n",
    "])\n",
    "\n",
    "# Function to remove stop words from tokens using the manually defined list\n",
    "def remove_manual_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in basic_stopwords]\n",
    "\n",
    "# Applying the stop word removal function using the manual list\n",
    "data['tokens_no_stopwords_manual'] = data['manual_tokens'].apply(remove_manual_stop_words)\n",
    "\n",
    "# Displaying the first few rows with tokens without stop words\n",
    "data[['manual_tokens', 'tokens_no_stopwords_manual']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b968c8d-b643-4180-a0ba-5f3e0aff49ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_no_stopwords_manual</th>\n",
       "      <th>simplified_lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hope, eveyone, could, get, fabulous, profit, ...</td>\n",
       "      <td>[hope, eveyone, could, get, fabulou, profit, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[free, signal, future, signal, buy, tia, usdt,...</td>\n",
       "      <td>[free, signal, future, signal, buy, tia, usdt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[another, 40%, profit, entry, buy, signal, cry...</td>\n",
       "      <td>[another, 40%, profit, entry, buy, signal, cry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[future, signal, buy, sol, usdt, exchange, ava...</td>\n",
       "      <td>[future, signal, buy, sol, usdt, exchange, ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[correct, way, starting, weekend, ntouched, ta...</td>\n",
       "      <td>[correct, way, start, weekend, ntouch, target,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          tokens_no_stopwords_manual  \\\n",
       "0  [hope, eveyone, could, get, fabulous, profit, ...   \n",
       "1  [free, signal, future, signal, buy, tia, usdt,...   \n",
       "2  [another, 40%, profit, entry, buy, signal, cry...   \n",
       "3  [future, signal, buy, sol, usdt, exchange, ava...   \n",
       "4  [correct, way, starting, weekend, ntouched, ta...   \n",
       "\n",
       "                        simplified_lemmatized_tokens  \n",
       "0  [hope, eveyone, could, get, fabulou, profit, f...  \n",
       "1  [free, signal, future, signal, buy, tia, usdt,...  \n",
       "2  [another, 40%, profit, entry, buy, signal, cry...  \n",
       "3  [future, signal, buy, sol, usdt, exchange, ava...  \n",
       "4  [correct, way, start, weekend, ntouch, target,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simplified lemmatization function (without using WordNet)\n",
    "# This function will perform a basic form of lemmatization based on simple heuristics\n",
    "\n",
    "def simplified_lemmatize(word):\n",
    "    # Basic rules for lemmatization (this is a very rudimentary approach)\n",
    "    if word.endswith('ing'):\n",
    "        return word[:-3]\n",
    "    if word.endswith('ed'):\n",
    "        return word[:-2]\n",
    "    if word.endswith('s'):\n",
    "        return word[:-1]\n",
    "    return word\n",
    "\n",
    "def apply_simplified_lemmatization(tokens):\n",
    "    return [simplified_lemmatize(word) for word in tokens]\n",
    "\n",
    "# Applying simplified lemmatization to the tokens\n",
    "data['simplified_lemmatized_tokens'] = data['tokens_no_stopwords_manual'].apply(apply_simplified_lemmatization)\n",
    "\n",
    "# Displaying the first few rows with simplified lemmatized tokens\n",
    "data[['tokens_no_stopwords_manual', 'simplified_lemmatized_tokens']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "481d340c-3513-43a6-9b5a-b6dacbd34252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   00  000  06  0d  10  100  1000  10x  11  12  ...  xrp  year  years  yet  \\\n",
       " 0   0    0   0   0   0    0     0    0   0   0  ...    0     0      0    0   \n",
       " 1   0    0   1   0   6    0     0    0   1   1  ...    0     0      0    0   \n",
       " 2   0    0   0   0   0    0     0    0   0   0  ...    0     0      0    0   \n",
       " 3   0    0   0   0   1    0     0    0   1   0  ...    0     0      0    0   \n",
       " 4   0    0   0   0   0    0     0    0   0   0  ...    0     0      0    0   \n",
       " \n",
       "    york  you  your  youtube  zero  zone  \n",
       " 0     0    0     0        0     0     0  \n",
       " 1     0    0     0        0     0     0  \n",
       " 2     0    0     0        0     0     0  \n",
       " 3     0    0     0        0     0     0  \n",
       " 4     0    0     0        0     0     0  \n",
       " \n",
       " [5 rows x 1000 columns],\n",
       "     00  000        06   0d        10  100  1000  10x        11        12  ...  \\\n",
       " 0  0.0  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.000000  0.000000  ...   \n",
       " 1  0.0  0.0  0.154434  0.0  0.464922  0.0   0.0  0.0  0.124710  0.109533  ...   \n",
       " 2  0.0  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.000000  0.000000  ...   \n",
       " 3  0.0  0.0  0.000000  0.0  0.097773  0.0   0.0  0.0  0.157358  0.000000  ...   \n",
       " 4  0.0  0.0  0.000000  0.0  0.000000  0.0   0.0  0.0  0.000000  0.000000  ...   \n",
       " \n",
       "    xrp  year  years  yet  york  you  your  youtube  zero  zone  \n",
       " 0  0.0   0.0    0.0  0.0   0.0  0.0   0.0      0.0   0.0   0.0  \n",
       " 1  0.0   0.0    0.0  0.0   0.0  0.0   0.0      0.0   0.0   0.0  \n",
       " 2  0.0   0.0    0.0  0.0   0.0  0.0   0.0      0.0   0.0   0.0  \n",
       " 3  0.0   0.0    0.0  0.0   0.0  0.0   0.0      0.0   0.0   0.0  \n",
       " 4  0.0   0.0    0.0  0.0   0.0  0.0   0.0      0.0   0.0   0.0  \n",
       " \n",
       " [5 rows x 1000 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Creating a CountVectorizer object for BoW\n",
    "bow_vectorizer = CountVectorizer(max_features=1000)  # Limiting to top 1000 features for simplicity\n",
    "bow_features = bow_vectorizer.fit_transform(data['cleaned_text']).toarray()\n",
    "\n",
    "# Creating a TfidfVectorizer object for TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Limiting to top 1000 features\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['cleaned_text']).toarray()\n",
    "\n",
    "# Converting the features into DataFrames for better readability\n",
    "bow_df = pd.DataFrame(bow_features, columns=bow_vectorizer.get_feature_names_out())\n",
    "tfidf_df = pd.DataFrame(tfidf_features, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Displaying the first few rows of each DataFrame\n",
    "bow_df.head(), tfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b62080d4-863a-47d1-993a-7cdcefcf9723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>the seed collector na new take on blockchain g...</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>report korean regulator approves issuance and...</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>lecksis is giving away $500 nare you ready to...</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>83% confess attraction to crypto fanatics on ...</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>asia based crypto exchange xrex secures in pri...</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>welcome to the world of limitless possibiliti...</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>join the festivities and win with duelbits $5...</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>discover defexa wallet join now for a chance ...</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>join the festivities and win with duelbits $5...</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>join the metaverse movement with this high po...</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>there is a good opportunity to make money on d...</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>there is a good opportunity to make money on d...</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>exciting news from the innovation hub of bang...</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>dwf labs invested $7 5 million in airdao for ...</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>addressable raises $7 5m to enable web3 compa...</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>bank of russia suggests tax cuts for long ter...</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>defexa wallet protect your crypto assets with...</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>cat inu pioneering memecoin ambitions with a b...</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>introducing cribx the future of web3 entertai...</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>holders of islamic coin are expecting new list...</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_text  sentiment_score  \\\n",
       "2874  the seed collector na new take on blockchain g...           0.9976   \n",
       "2663   report korean regulator approves issuance and...           0.9973   \n",
       "1802   lecksis is giving away $500 nare you ready to...           0.9971   \n",
       "2081   83% confess attraction to crypto fanatics on ...           0.9968   \n",
       "1532  asia based crypto exchange xrex secures in pri...           0.9967   \n",
       "1594   welcome to the world of limitless possibiliti...           0.9961   \n",
       "2509   join the festivities and win with duelbits $5...           0.9961   \n",
       "1647   discover defexa wallet join now for a chance ...           0.9961   \n",
       "2502   join the festivities and win with duelbits $5...           0.9961   \n",
       "2088   join the metaverse movement with this high po...           0.9958   \n",
       "4700  there is a good opportunity to make money on d...           0.9957   \n",
       "4233  there is a good opportunity to make money on d...           0.9957   \n",
       "1922   exciting news from the innovation hub of bang...           0.9956   \n",
       "1761   dwf labs invested $7 5 million in airdao for ...           0.9955   \n",
       "2089   addressable raises $7 5m to enable web3 compa...           0.9954   \n",
       "2712   bank of russia suggests tax cuts for long ter...           0.9953   \n",
       "1616   defexa wallet protect your crypto assets with...           0.9951   \n",
       "429   cat inu pioneering memecoin ambitions with a b...           0.9950   \n",
       "2447   introducing cribx the future of web3 entertai...           0.9948   \n",
       "5002  holders of islamic coin are expecting new list...           0.9947   \n",
       "\n",
       "     sentiment_category  \n",
       "2874           positive  \n",
       "2663           positive  \n",
       "1802           positive  \n",
       "2081           positive  \n",
       "1532           positive  \n",
       "1594           positive  \n",
       "2509           positive  \n",
       "1647           positive  \n",
       "2502           positive  \n",
       "2088           positive  \n",
       "4700           positive  \n",
       "4233           positive  \n",
       "1922           positive  \n",
       "1761           positive  \n",
       "2089           positive  \n",
       "2712           positive  \n",
       "1616           positive  \n",
       "429            positive  \n",
       "2447           positive  \n",
       "5002           positive  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initializing VADER's SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get the compound sentiment score\n",
    "def get_sentiment(text):\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "\n",
    "# Applying the sentiment analysis to the cleaned text\n",
    "data['sentiment_score'] = data['cleaned_text'].apply(get_sentiment)\n",
    "\n",
    "# Categorizing sentiment into positive, neutral, or negative based on the compound score\n",
    "data['sentiment_category'] = data['sentiment_score'].apply(lambda score: 'positive' if score > 0.05 else ('negative' if score < -0.05 else 'neutral'))\n",
    "\n",
    "# Displaying the first few rows with sentiment scores and categories\n",
    "data[['cleaned_text', 'sentiment_score', 'sentiment_category']].sort_values('sentiment_score', ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714a5f14-2d98-47bf-a524-5d146b66189f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a4fd5-0c87-4fce-883c-b8ec9adc8484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0070b1e-07c4-4d56-b8e9-81d19d836237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
